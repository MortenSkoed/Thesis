{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "dK7BXfm4UG4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJlSykS1Hxhp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "n0ZhNkkxUIiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "path1 = \"/content/drive/MyDrive/Thesis/Data/Merging CleanPrice & Features.csv\"\n",
        "price = pd.read_csv(path1, sep=',')\n",
        "\n",
        "columns = price.copy()\n",
        "price.set_index('Date', inplace=True)\n",
        "RawData = price.copy()"
      ],
      "metadata": {
        "id": "33aT9Vsoi4IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Mean Benchmark"
      ],
      "metadata": {
        "id": "U7O9QjJmG5mO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making rolling mean benchmark\n",
        "columns = ['GEO_Name', 'Log_Return_h1', 'Log_Return_h3', 'Log_Return_h6', 'Log_Return_h12']\n",
        "actual_data = RawData[columns].copy()\n",
        "mean_dfs = []\n",
        "\n",
        "for name, group in actual_data.groupby('GEO_Name'):\n",
        "    group['Mean_h1'] = group['Log_Return_h1'].rolling(window=330).mean().shift(1)\n",
        "    group['Mean_h3'] = group['Log_Return_h3'].rolling(window=330).mean().shift(3)\n",
        "    group['Mean_h6'] = group['Log_Return_h6'].rolling(window=330).mean().shift(6)\n",
        "    group['Mean_h12'] = group['Log_Return_h12'].rolling(window=330).mean().shift(12)\n",
        "    # Append the results to df\n",
        "    mean_dfs.append(group)\n",
        "\n",
        "actual_data = pd.concat(mean_dfs).reset_index()\n",
        "MeanBenchmark = actual_data[['Date', 'GEO_Name', 'Mean_h1', 'Mean_h3', 'Mean_h6', 'Mean_h12']].rename(columns={'GEO_Name': 'state', 'Mean_h1': 'h1', 'Mean_h3': 'h3', 'Mean_h6': 'h6', 'Mean_h12': 'h12'})"
      ],
      "metadata": {
        "id": "vOnwPQt3i4ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading predictions and corresponding actuals\n",
        "actuals = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/AR(1)Actuals.csv\", sep=',')\n",
        "AR_1 = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/AR(1)Predictions.csv\", sep=',')\n",
        "AR_optimal = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/AR(Optimal)Predictions.csv\", sep=',')\n",
        "ARIMA = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/ARIMAPredictions.csv\", sep=',')\n",
        "RandomForest = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/RandomForestPredictions.csv\", sep=',')\n",
        "XGBoost = pd.read_csv(\"/content/drive/MyDrive/Thesis/Models/Predictions/XGBoostPredictions.csv\", sep=',')"
      ],
      "metadata": {
        "id": "jFktvYWpH35N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the date column to date\n",
        "actuals.rename(columns={'PredictionDate': 'Date'}, inplace=True)\n",
        "AR_1.rename(columns={'PredictionDate': 'Date'}, inplace=True)\n",
        "AR_optimal.rename(columns={'PredictionDate': 'Date'}, inplace=True)\n",
        "ARIMA.rename(columns={'PredictionDate': 'Date'}, inplace=True)\n",
        "\n",
        "RandomForest.rename(columns={'OriginalIndex': 'Date'}, inplace=True)\n",
        "XGBoost.rename(columns={'OriginalIndex': 'Date'}, inplace=True)\n",
        "\n",
        "RandomForest.rename(columns={'State': 'state'}, inplace=True)\n",
        "XGBoost.rename(columns={'State': 'state'}, inplace=True)"
      ],
      "metadata": {
        "id": "9cwlhv7_H6f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Combination forecasts\n",
        "combined_df1 = pd.concat([AR_optimal, ARIMA, RandomForest, XGBoost], ignore_index=True)\n",
        "averaged_predictions1 = combined_df1.groupby(['Date', 'state']).mean().reset_index()\n",
        "Combination_AR_1 = averaged_predictions1.sort_values(by=['state', 'Date']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Yl1G1xcRH7uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing 'USA' from the predictions and actuals\n",
        "actuals = actuals[actuals['state'] != 'USA']\n",
        "AR_1 = AR_1[AR_1['state'] != 'USA']\n",
        "AR_optimal = AR_optimal[AR_optimal['state'] != 'USA']\n",
        "ARIMA = ARIMA[ARIMA['state'] != 'USA']\n",
        "RandomForest = RandomForest[RandomForest['state'] != 'USA']\n",
        "XGBoost = XGBoost[XGBoost['state'] != 'USA']\n",
        "Combination_AR_1 = Combination_AR_1[Combination_AR_1['state'] != 'USA']\n",
        "MeanBenchmark = MeanBenchmark[MeanBenchmark['state'] != 'USA']"
      ],
      "metadata": {
        "id": "ItZ5A4SAH-DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the dataframes to datetime\n",
        "actuals['Date'] = pd.to_datetime(actuals['Date'])\n",
        "AR_1['Date'] = pd.to_datetime(AR_1['Date'])\n",
        "AR_optimal['Date'] = pd.to_datetime(AR_optimal['Date'])\n",
        "ARIMA['Date'] = pd.to_datetime(ARIMA['Date'])\n",
        "RandomForest['Date'] = pd.to_datetime(RandomForest['Date'])\n",
        "XGBoost['Date'] = pd.to_datetime(XGBoost['Date'])\n",
        "Combination_AR_1['Date'] = pd.to_datetime(Combination_AR_1['Date'])\n",
        "MeanBenchmark['Date'] = pd.to_datetime(MeanBenchmark['Date'])"
      ],
      "metadata": {
        "id": "YOH6ebf4H_kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the dataframes to have the same length\n",
        "actuals = actuals[actuals['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "AR_1 = AR_1[AR_1['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "AR_optimal = AR_optimal[AR_optimal['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "ARIMA = ARIMA[ARIMA['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "RandomForest = RandomForest[RandomForest['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "XGBoost = XGBoost[XGBoost['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "Combination_AR_1 = Combination_AR_1[Combination_AR_1['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)\n",
        "MeanBenchmark = MeanBenchmark[MeanBenchmark['Date'] >= pd.Timestamp('2008-07-01')].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-MbJftiKH_0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE over time vs. Actuals"
      ],
      "metadata": {
        "id": "4XboJUq-IDQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of models used in making MSE over time\n",
        "models = {\n",
        "    'XGBoost': XGBoost,\n",
        "    'Random Forest': RandomForest,\n",
        "    'AR(Optimal)': AR_optimal,\n",
        "    'ARIMA': ARIMA,\n",
        "    'Combination': Combination_AR_1\n",
        "}"
      ],
      "metadata": {
        "id": "QwXoNCGgICpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "horizons = ['h1', 'h3', 'h6', 'h12']\n",
        "mse_entries = []\n",
        "\n",
        "for model_name, df_model in models.items():\n",
        "    for horizon in horizons:\n",
        "        # Combining actuals and predictions into one df\n",
        "        combined = pd.DataFrame({\n",
        "            'Date': actuals['Date'],\n",
        "            'State': actuals['state'],\n",
        "            'Actuals': actuals[horizon],\n",
        "            'Predictions': df_model[horizon]\n",
        "        }).dropna()\n",
        "\n",
        "        # Calculate MSE\n",
        "        combined['Squared_Error'] = (combined['Actuals'] - combined['Predictions']) ** 2\n",
        "        mse_by_date = combined.groupby('Date')['Squared_Error'].mean().reset_index()\n",
        "\n",
        "        # Calculating cumulative MSE and append to one df\n",
        "        mse_by_date['Cumulative_Squared_Difference'] = mse_by_date['Squared_Error'].cumsum()\n",
        "        mse_by_date['Model'] = model_name\n",
        "        mse_by_date['Horizon'] = horizon\n",
        "        mse_entries.extend(mse_by_date.to_dict('records'))\n",
        "\n",
        "cumulative_mse_df = pd.DataFrame(mse_entries)"
      ],
      "metadata": {
        "id": "35xGuiBgorme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE over time vs. MeanBenchmark"
      ],
      "metadata": {
        "id": "hgK25hVmXD2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of model dataframes and their identifiers\n",
        "models = {\n",
        "    'XGBoost': XGBoost,\n",
        "    'Random Forest': RandomForest,\n",
        "    'AR(Optimal)': AR_optimal,\n",
        "    'ARIMA': ARIMA,\n",
        "    'Combination': Combination_AR_1,\n",
        "    'MeanBenchmark': MeanBenchmark\n",
        "}"
      ],
      "metadata": {
        "id": "SH4Bl5LqXHlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "horizons = ['h1', 'h3', 'h6', 'h12']\n",
        "benchmark_model_name = 'MeanBenchmark'\n",
        "entries = []\n",
        "benchmark_data = {}\n",
        "\n",
        "# Combining df's\n",
        "for horizon in horizons:\n",
        "    combined_benchmark = pd.DataFrame({\n",
        "        'Date': actuals['Date'],\n",
        "        'State': actuals['state'],\n",
        "        'Actuals': actuals[horizon],\n",
        "        'Benchmark_Predictions': models[benchmark_model_name][horizon]\n",
        "    }).dropna()\n",
        "\n",
        "    avg_benchmark = combined_benchmark.groupby('Date').agg({\n",
        "        'Benchmark_Predictions': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    benchmark_data[horizon] = avg_benchmark\n",
        "\n",
        "# Iterate on each model excluding the benchmark\n",
        "for model_name, df_model in models.items():\n",
        "    if model_name != benchmark_model_name:\n",
        "        for horizon in horizons:\n",
        "            combined = pd.DataFrame({\n",
        "                'Date': actuals['Date'],\n",
        "                'State': actuals['state'],\n",
        "                'Actuals': actuals[horizon],\n",
        "                'Predictions': df_model[horizon]\n",
        "            }).dropna()\n",
        "\n",
        "            # Calculate MSE\n",
        "            combined['Squared_Error'] = (combined['Actuals'] - combined['Predictions']) ** 2\n",
        "            mse_by_date = combined.groupby('Date')['Squared_Error'].mean().reset_index()\n",
        "            mse_by_date = mse_by_date.join(benchmark_data[horizon].set_index('Date'), on='Date')\n",
        "            mse_by_date['Squared_Difference'] = mse_by_date['Benchmark_Predictions'] ** 2 - combined.groupby('Date')['Predictions'].mean().reset_index()['Predictions'] ** 2\n",
        "\n",
        "            # Storing results\n",
        "            for index, row in mse_by_date.iterrows():\n",
        "                entries.append({\n",
        "                    'Model': model_name,\n",
        "                    'Horizon': horizon,\n",
        "                    'Date': row['Date'],\n",
        "                    'Squared_Error': row['Squared_Error'],\n",
        "                    'Squared_Difference': row['Squared_Difference']\n",
        "                })\n",
        "\n",
        "# Making cumulative MSE\n",
        "result_Mean = pd.DataFrame(entries)\n",
        "result_Mean.sort_values(by=['Model', 'Horizon', 'Date'], inplace=True)\n",
        "result_Mean['Cumulative_Squared_Difference'] = result_Mean.groupby(['Model', 'Horizon'])['Squared_Difference'].cumsum()"
      ],
      "metadata": {
        "id": "kCRPKovCrenM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models vs. AR(1)"
      ],
      "metadata": {
        "id": "oh_Bgfv2yyW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of model dataframes and their identifiers\n",
        "models = {\n",
        "    'AR_1': AR_1,\n",
        "    'XGBoost': XGBoost,\n",
        "    'Random Forest': RandomForest,\n",
        "    'AR(Optimal)': AR_optimal,\n",
        "    'ARIMA': ARIMA,\n",
        "    'Combination': Combination_AR_1,\n",
        "}"
      ],
      "metadata": {
        "id": "9ntKQtrIy45H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "horizons = ['h1', 'h3', 'h6', 'h12']\n",
        "benchmark_model_name = 'AR_1'\n",
        "entries = []\n",
        "benchmark_data = {}\n",
        "\n",
        "# Combining df's\n",
        "for horizon in horizons:\n",
        "    combined_benchmark = pd.DataFrame({\n",
        "        'Date': actuals['Date'],\n",
        "        'State': actuals['state'],\n",
        "        'Actuals': actuals[horizon],\n",
        "        'Benchmark_Predictions': models[benchmark_model_name][horizon]\n",
        "    }).dropna()\n",
        "\n",
        "    avg_benchmark = combined_benchmark.groupby('Date').agg({\n",
        "        'Benchmark_Predictions': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    benchmark_data[horizon] = avg_benchmark\n",
        "\n",
        "# Iterate on each model excluding the benchmark\n",
        "for model_name, df_model in models.items():\n",
        "    if model_name != benchmark_model_name:\n",
        "        for horizon in horizons:\n",
        "            combined = pd.DataFrame({\n",
        "                'Date': actuals['Date'],\n",
        "                'State': actuals['state'],\n",
        "                'Actuals': actuals[horizon],\n",
        "                'Predictions': df_model[horizon]\n",
        "            }).dropna()\n",
        "\n",
        "            # Calculate MSE\n",
        "            combined['Squared_Error'] = (combined['Actuals'] - combined['Predictions']) ** 2\n",
        "            mse_by_date = combined.groupby('Date')['Squared_Error'].mean().reset_index()\n",
        "            mse_by_date = mse_by_date.join(benchmark_data[horizon].set_index('Date'), on='Date')\n",
        "            mse_by_date['Squared_Difference'] = mse_by_date['Benchmark_Predictions'] ** 2 - combined.groupby('Date')['Predictions'].mean().reset_index()['Predictions'] ** 2\n",
        "\n",
        "            # Storing results\n",
        "            for index, row in mse_by_date.iterrows():\n",
        "                entries.append({\n",
        "                    'Model': model_name,\n",
        "                    'Horizon': horizon,\n",
        "                    'Date': row['Date'],\n",
        "                    'Squared_Error': row['Squared_Error'],\n",
        "                    'Squared_Difference': row['Squared_Difference']\n",
        "                })\n",
        "\n",
        "# Making cumulative MSE\n",
        "result_AR = pd.DataFrame(entries)\n",
        "result_AR.sort_values(by=['Model', 'Horizon', 'Date'], inplace=True)\n",
        "result_AR['Cumulative_Squared_Difference'] = result_AR.groupby(['Model', 'Horizon'])['Squared_Difference'].cumsum()"
      ],
      "metadata": {
        "id": "LA8HXQQrEcOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot"
      ],
      "metadata": {
        "id": "XypBXc15GCUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing units\n",
        "result_Mean['Cumulative_Squared_Difference'] = result_Mean['Cumulative_Squared_Difference']*100\n",
        "result_AR['Cumulative_Squared_Difference'] = result_AR['Cumulative_Squared_Difference']*100\n",
        "cumulative_mse_df['Cumulative_Squared_Difference'] = cumulative_mse_df['Cumulative_Squared_Difference']*100\n",
        "\n",
        "# Setting font styles\n",
        "plt.rcParams.update({'font.size': 8, 'font.style': 'normal'})\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(11, 16), sharex=True)\n",
        "\n",
        "# Setting horizon, benchmark and models\n",
        "horizons = ['h1', 'h3', 'h6', 'h12']\n",
        "y_label = [r'$h_1$', r'$h_3$', r'$h_6$', r'$h_{12}$']\n",
        "benchmarks = ['Actuals', 'AR(1)', 'Mean']\n",
        "models = ['XGBoost', 'Random Forest', 'AR(Optimal)', 'ARIMA', 'Combination']\n",
        "\n",
        "# Collection of dataframes\n",
        "data_sources = {\n",
        "    'Actuals': cumulative_mse_df,\n",
        "    'AR(1)': result_AR,\n",
        "    'Mean': result_Mean\n",
        "}\n",
        "\n",
        "# Plotting the data\n",
        "for i, horizon in enumerate(horizons):\n",
        "    for j, benchmark in enumerate(benchmarks):\n",
        "        ax = axes[i, j]\n",
        "        df = data_sources[benchmark]\n",
        "        min_y = float('inf')\n",
        "        max_y = float('-inf')\n",
        "\n",
        "        for model in models:\n",
        "            subset = df[(df['Model'] == model) & (df['Horizon'] == horizon)]\n",
        "            if not subset.empty:\n",
        "                ax.plot(subset['Date'], subset['Cumulative_Squared_Difference'], label=model, linewidth=0.9)\n",
        "                min_y = min(min_y, subset['Cumulative_Squared_Difference'].min())\n",
        "                max_y = max(max_y, subset['Cumulative_Squared_Difference'].max())\n",
        "\n",
        "        if i == 0:\n",
        "            ax.set_title(benchmark, fontsize=12)\n",
        "            if j == 0:\n",
        "                ax.set_ylim(-0.05, 0.55)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "\n",
        "            elif j == 1:\n",
        "                ax.set_ylim(-0.015, 0.165)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "\n",
        "            elif j == 2:\n",
        "                ax.set_ylim(-0.325, 0.025)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='lower left', prop={'size': 8}, frameon=False)\n",
        "\n",
        "        elif i == 1:\n",
        "            if j == 0:\n",
        "                ax.set_ylim(-0.25, 6.25)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "\n",
        "            elif j == 1:\n",
        "                ax.set_ylim(-0.075, 1.45)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "\n",
        "            elif j == 2:\n",
        "                ax.set_ylim(-2.1, 0.1)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(0.4))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='lower left', prop={'size': 8}, frameon=False)\n",
        "        elif i == 2:\n",
        "            if j == 0:\n",
        "                ax.set_ylim(-1.3, 21.3)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "            elif j == 1:\n",
        "                ax.set_ylim(-0.25, 3.25)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "            elif j == 2:\n",
        "                ax.set_ylim(-5.4, 0.4)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='lower left', prop={'size': 8}, frameon=False)\n",
        "        elif i == 3:\n",
        "            if j == 0:\n",
        "                ax.set_ylim(-5, 75)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='upper left', prop={'size': 8}, frameon=False)\n",
        "                ax.set_xlabel('Year', rotation=0, labelpad=10, fontsize=12)\n",
        "            elif j == 1:\n",
        "                ax.set_ylim(-3.5, 5)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(1.5))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='lower left', prop={'size': 8}, frameon=False)\n",
        "                ax.set_xlabel('Year', rotation=0, labelpad=10, fontsize=12)\n",
        "            elif j == 2:\n",
        "                ax.set_ylim(-15, 1)\n",
        "                ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.1f'))\n",
        "                ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
        "                ax.tick_params(axis='y', labelsize=9)\n",
        "                ax.legend(loc='lower left', prop={'size': 8}, frameon=False)\n",
        "                ax.set_xlabel('Year', rotation=0, labelpad=10, fontsize=12)\n",
        "\n",
        "        if j == 0:\n",
        "            ax.set_ylabel(f'{y_label[i]} CMSE', labelpad=10, fontsize=12)\n",
        "\n",
        "        # Date formatting\n",
        "        ax.xaxis.set_major_locator(mdates.YearLocator(4))\n",
        "        ax.xaxis.set_minor_locator(mdates.YearLocator(1))\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha=\"center\", fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.9, wspace=0.2, hspace=0.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNnV_NNIF5gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "zqdKiYutUU-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}